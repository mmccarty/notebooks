{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590f66df-a318-4a1e-be3b-e4aa930a2cc9",
   "metadata": {},
   "source": [
    "# Getting Started with Optuna, RAPIDS and Dask-Optuna for HPO\n",
    "Hyperparameter optimization (HPO) automates the process of picking values for the hyperparameters of a machine learning algorithm to improve model performance. This can help boost the model accuracy greatly, but can be resource-intensive, as it may require training the model for hundreds of hyperparameter combinations. Let's take a look at how we can use Optuna and RAPIDS to make HPO less time-consuming.\n",
    "## RAPIDS\n",
    "The RAPIDS framework provides a suite of libraries to execute end-to-end data science pipelines entirely on GPUs. One of the libraries in this framework is cuML, which implements common machine learning models with a scikit-learn-compatible API and a GPU-accelerated backend. You can learn more about RAPIDS [here](https://rapids.ai/about.html).\n",
    "## Optuna\n",
    "[Optuna](https://optuna.readthedocs.io/en/stable/) is a lightweight framework for automatic hyperparameter optimization. It provides a define-by-run API, which makes it easy to adapt to any already existing code that we have and enables high modularity along with the flexibility to construct hyperparameter spaces dynamically. By simply wrapping the objective function with Optuna, we can perform a parallel-distributed HPO search over a search space as we'll see in this notebook.\n",
    "## Dask-Optuna\n",
    "[Dask-Optuna](https://jrbourbeau.github.io/dask-optuna/#) is a library to help integrate Optuna's distributed optimizations to run trials on a Dask Cluster. It provides a `dask_optuna.DaskStorage` that wraps the Optuna storage class. This class helps extend in-memory computations to workers in the cluster.\n",
    " \n",
    "In this notebook, we'll use BNP Paribas Cardif Claims Management dataset from Kaggle to predict if a claim will receive accelerated approval or not. We'll explore how to use Optuna with RAPIDS in combination with Dask to run multi-GPU HPO experiments that can yield results faster than CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e00c06-7a7e-4cbb-b5d6-b56e44b1002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Run this cell to install optuna and dask_optuna\n",
    "# !pip install optuna\n",
    "# !pip install dask_optuna\n",
    "\n",
    "# ## The plotting libraries\n",
    "# !pip install plotly\n",
    "# !pip install -U kaleido\n",
    "# !pip install 'bokeh<2.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0236fbd-c070-4c8c-9f0d-9cd5d4d5aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import cudf\n",
    "import cuml\n",
    "import dask_cudf\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "import dask\n",
    "import dask_optuna\n",
    "import xgboost as xgb\n",
    "\n",
    "from cuml.model_selection import train_test_split\n",
    "from cuml.metrics import log_loss\n",
    "\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client, wait, performance_report\n",
    "\n",
    "from joblib import parallel_backend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a2f7b-6b78-4f3c-8bfa-942aeb8ee3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for timing blocks of code.\n",
    "@contextmanager\n",
    "def timed(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    t1 = time.time()\n",
    "    print(\"..%-24s:  %8.4f\" % (name, t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb891c5-859a-4d75-a17c-98632b6bab3c",
   "metadata": {},
   "source": [
    "## Set up CUDA Cluster\n",
    "\n",
    "We start a local cluster and keep it ready for running distributed tasks with dask. The dask scheduler can help leverage multiple nodes available on the cluster.\n",
    "\n",
    "[LocalCUDACluster](https://github.com/rapidsai/dask-cuda) launches one Dask worker for each GPU in the current systems. It's developed as a part of the RAPIDS project. Learn More:\n",
    "- [Setting up Dask](https://docs.dask.org/en/latest/setup.html)\n",
    "- [Dask Client](https://distributed.dask.org/en/latest/client.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ddd56-b6be-4044-9b0c-89c9bee258bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will use all GPUs on the local host by default\n",
    "cluster = LocalCUDACluster(threads_per_worker=1, ip=\"\", dashboard_address=\"8081\")\n",
    "c = Client(cluster)\n",
    "\n",
    "# Query the client for all connected workers\n",
    "workers = c.has_what().keys()\n",
    "n_workers = len(workers)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4825c-8b44-439e-a712-0ad47d5f4dc3",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "## Data Acquisition\n",
    "Dataset can be acquired from Kaggle: [BNP Paribas Cardif Claims Management](https://www.kaggle.com/c/bnp-paribas-cardif-claims-management/data). To download the dataset:\n",
    " \n",
    "1. Create a `data` folder in the current directory. If you're downloading it elsewhere, be sure to change `data_dir` to point to the approproate location.\n",
    " \n",
    "2. Follow the instructions here to: [Set-up the Kaggle API](https://github.com/Kaggle/kaggle-api)\n",
    " \n",
    "3. Run the following command in the command line in the `data` folder.\n",
    " \n",
    "    `kaggle competitions download -c bnp-paribas-cardif-claims-management`\n",
    " \n",
    " \n",
    "This is an anonymized dataset containing categorical and numerical values for claims received by BNP Paribas Cardif.  The \"target\" column in the train set is the variable to predict. It is equal to 1 for claims suitable for an accelerated approval. The task is to predict whether a claim will be suitable for accelerated approval or not. We'll only use the `train.csv` file as `test.csv` does not have a target column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0188c6ab-e284-4023-bb8d-b6402a6a43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_name = 'train.csv' \n",
    "\n",
    "data_dir = \"data/\"\n",
    "INPUT_FILE = os.path.join(data_dir, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5306bb-a944-4874-beeb-296f7da5533d",
   "metadata": {},
   "source": [
    "Select the `N_TRIALS` for the number of runs of HPO trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa064b-d80c-4bc1-9d0b-d37a723a713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "\n",
    "N_TRIALS = 150\n",
    "\n",
    "df = cudf.read_csv(INPUT_FILE)\n",
    "\n",
    "# Drop non-numerical data and fill NaNs before passing to cuML RF\n",
    "CAT_COLS = list(df.select_dtypes('object').columns)\n",
    "df = df.drop(CAT_COLS, axis=1)\n",
    "df = df.fillna(0)\n",
    "\n",
    "df = df.astype(\"float32\")\n",
    "X, y = df.drop([\"target\"], axis=1), df[\"target\"].astype('int32')\n",
    "\n",
    "study_name = \"dask_optuna_xgb_log_loss_tpe\"\n",
    "storage_name = \"sqlite:///study_stores.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f350960-0966-4879-a168-1c5826ad4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{X.values.nbytes / 1e6} MB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e7696c-fc99-45bc-888d-d8dffc7e903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3c391-9a2c-455e-90ec-e625eabd8680",
   "metadata": {},
   "source": [
    "# Training and Evaluation\n",
    "\n",
    "The `train_and_eval` function accepts the different parameters to try out. This function should look very similar to any ML workflow. We'll use this function within the Optuna `objective` function to show how easily we can fit an existing workflow into the Optuna work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f5e24-b0d5-4463-9019-62f91fd09374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(X_param, y_param, X_valid, y_valid, params):\n",
    "    \"\"\"\n",
    "        Splits the given data into train and test split to train and evaluate the model\n",
    "        for the params parameters.\n",
    "        \n",
    "        Params\n",
    "        ______\n",
    "        \n",
    "        X_param:  DataFrame. \n",
    "                  The data to use for training and testing. \n",
    "        y_param:  Series. \n",
    "                  The label for training\n",
    "\n",
    "        Returns\n",
    "        score: log loss of the fitted model\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_param,\n",
    "                                                        y_param,\n",
    "                                                        random_state=42)\n",
    "    \n",
    "    \n",
    "    params[\"tree_method\"] = \"gpu_hist\"\n",
    "        \n",
    "    bst = xgb.XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        **params)\n",
    "\n",
    "    bst.fit(X_train,\n",
    "            y_train,\n",
    "            early_stopping_rounds=100,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            verbose=False)\n",
    "    score = bst.score(X_valid.to_numpy(), y_valid.to_numpy())\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c014c6ea-559a-4a10-a8b9-a12111600abb",
   "metadata": {},
   "source": [
    "For a baseline number, let's see what the default performance of the model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e794dd-4534-4e42-80ad-73da3fe0e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42)\n",
    "print(\"Score with default parameters : \",train_and_eval(X_train, y_train, X_valid, y_valid, {}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac831e-0b80-4893-a05d-6a6fc6177549",
   "metadata": {},
   "source": [
    "## Objective Function\n",
    " \n",
    "The objective function will be the one we optimize in [Optuna Study](https://optuna.readthedocs.io/en/stable/reference/study.html). The objective function tries out specified values for the parameters that we are tuning and returns the score obtained with those parameters. These results will be aggregated in `study.trials_dataframes()`. \n",
    " \n",
    "Let's define the objective function for this HPO task by making use of the `train_and_eval()`. You can see that we simply choose a value for the parameters and call the `train_and_eval` method, making Optuna very easy to use in an existing workflow.\n",
    " \n",
    "The objective function does not need to be changed when switching to different [samplers](https://optuna.readthedocs.io/en/stable/reference/samplers.html), which are built-in options in Optuna to enable the selection of different sampling algorithms that optuna provides. Some of the available ones include - GridSampler, RandomSampler, TPESampler, etc. We'll use TPESampler for this demo, but feel free to try different samplers to notice the changes in performance. \n",
    " \n",
    "\n",
    "[Tree-Structured Parzen Estimators](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.TPESampler.html#optuna.samplers.TPESampler) or TPE works by fitting two  Gaussian Mixture Model during each trial - one to the set of parameter values associated with the best objective values,\n",
    "and another to the remaining parameter values. It chooses the parameter value that maximizes the ratio between the two GMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bfc887-50c7-4abb-bb22-e64ac386c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_param, y_param):\n",
    "    # Note that there are more parameters for RF, and tweaking those will\n",
    "    # improve performance too. But for simplicity, we will use just\n",
    "    # max_depth and n_estimators.\n",
    "\n",
    "    params = {\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 24),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 1e-8, 1.0, log=True),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True),\n",
    "        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"]),\n",
    "    }\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_param,\n",
    "                                                          y_param,\n",
    "                                                          random_state=42)\n",
    "\n",
    "    score = train_and_eval(X_train,\n",
    "                           y_train,\n",
    "                           X_valid,\n",
    "                           y_valid,\n",
    "                           params)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f39508-115a-4ace-a6f8-09d4928b87f3",
   "metadata": {},
   "source": [
    "## HPO Trials and Study\n",
    " \n",
    "Optuna uses [study](https://optuna.readthedocs.io/en/stable/reference/study.html) and [trials](https://optuna.readthedocs.io/en/stable/reference/trial.html) to keep track of the HPO experiments. Put simply, a trial is a single call of the objective function while a set of trials make up a study. We will pick the best observed trial from a study to get the best parameters that were used in that run.\n",
    "\n",
    "Here, dask_optuna Storage class is used to set up a storage shared by all workers in the cluster. Optuna also requires the use of a storage to run distributed optimization runs. Learn more about what storages can be used [here](https://optuna.readthedocs.io/en/stable/tutorial/distributed.html)\n",
    "\n",
    "`optuna.create_study` is used to set up the study. As you can see, it specifies the study name, sampler to be used, the direction of the study, and the storage.\n",
    "With just a few lines of code, we have set up a distributed HPO experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7744c124-5d5d-4002-9b5d-b7935a7293fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with timed(\"dask_optuna\"):\n",
    "    # Create a study using Dask-compatible storage\n",
    "    storage = dask_optuna.DaskStorage(storage_name)\n",
    "    study = optuna.create_study(sampler=optuna.samplers.TPESampler(),\n",
    "                                study_name=study_name,\n",
    "                                direction=\"minimize\",\n",
    "                                storage=storage,\n",
    "                                load_if_exists=True)\n",
    "    # Optimize in parallel on your Dask cluster\n",
    "    with parallel_backend(\"dask\"):\n",
    "        study.optimize(lambda trial: objective(trial, X, y),\n",
    "                           n_trials=N_TRIALS,\n",
    "                           n_jobs=6)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "study.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82112d9a-b15f-4d2a-bd93-ed011f4e2b4c",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Optuna provides an easy way to visualize the trials by integrating some graphs with the library. Here we will explore a few of them to see how our study did.\n",
    "\n",
    "Read more about visualizations [here](https://optuna.readthedocs.io/en/stable/reference/visualization.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d69c8-3ea1-46d4-91c1-ee6891c5e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d8be6-bbb4-47d5-9a17-a6aa90ada09b",
   "metadata": {},
   "source": [
    "Let's look at the importance of each parameter to the performance of the model. This illustrates the impact that the hyperparameters have on the accuracy. We can see that `penalty` was most useful in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d579ceb1-1934-4d7a-9ca4-e298ec4ac8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = optuna.visualization.plot_param_importances(study)\n",
    "Image(f.to_image(format=\"png\", engine='kaleido'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bd232d-04c8-4a31-86c9-e9e64b6c96e5",
   "metadata": {},
   "source": [
    "Let's look at how the optimisation within the study progressed with the history plot for the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f7ab25-d280-4e9b-bb3b-4ade32d21ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = optuna.visualization.plot_optimization_history(study)\n",
    "Image(f.to_image(format=\"png\", engine='kaleido'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789662bd-ca29-4e17-a7d3-251b27273149",
   "metadata": {},
   "source": [
    "The following is a parallel coordinate plot to understand the relationships between the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa7eb2-de48-4f20-9bed-f106c9e71a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = optuna.visualization.plot_parallel_coordinate(study, params=['max_depth', 'eta', 'gamma', 'grow_policy', 'alpha'])\n",
    "Image(f.to_image(format=\"png\", engine='kaleido'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c02c3b0-4c93-4fa2-8d6e-8b70e0ea0c81",
   "metadata": {},
   "source": [
    "## Optuna Dashboard\n",
    "\n",
    "Optuna provides dashboard to visualise the results. You can read more about it [here](https://optuna.readthedocs.io/en/stable/reference/cli.html)\n",
    "\n",
    "To visualize the optuna dashboard run `optuna dashboard --study-name {study_name} --storage \"{storage_name}\"`. We will use the `-o` option to save the dashboard to a html file.\n",
    "\n",
    "For this experiement run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb35471-836a-448f-9157-c727db0786ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Run the following to download the dashboard to dashboard.html: \\n\\n\\t\"\n",
    "      f\"optuna dashboard --study-name {study_name} --storage '{storage_name}' -o dashboard.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c02c2bc-02cf-4813-ad9b-4c751764302d",
   "metadata": {},
   "source": [
    "## Concluding Remarks\n",
    " \n",
    "This notebook shows how RAPIDS and Optuna can be used along with dask to run multi-GPU HPO jobs, and can be used as a starting point for anyone wanting to get started with the framework. It also provides some visualization tools to interpret the results. We have seen how by just adding a few lines of code we were able to integrate the libraries for a muli-GPU HPO runs. This can also be scaled to multiple nodes.\n",
    " \n",
    "## Next Steps\n",
    " \n",
    "This is done on a small dataset, you are encouraged to test out on larger data with more range for the parameters too. These experiments can yield performance improvements. Refer to other examples in the [rapidsai/cloud-ml-examples](https://github.com/rapidsai/cloud-ml-examples) repository.\n",
    " \n",
    "## Resources\n",
    "[Hyperparameter Tuning in Python](https://towardsdatascience.com/hyperparameter-tuning-c5619e7e6624)\n",
    "\n",
    "[Overview of Hyperparameter tuning](https://cloud.google.com/ai-platform/training/docs/hyperparameter-tuning-overview)\n",
    "\n",
    "[How to make your model awesome with Optuna](https://towardsdatascience.com/how-to-make-your-model-awesome-with-optuna-b56d490368af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577fc15-1365-402b-8fe1-2f602a367839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
